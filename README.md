# Basalt: Robust Federated Learning Framework for Defending Byzantine Attacks in Non-IID Data

Federated learning (FL), an emerging distributed learning paradigm, has been widely employed in data mining to extract valuable information from vast amounts of data. However, the distributed nature of FL makes it susceptible to Byzantine attacks, where malicious attackers can intentionally behave in a malicious  manner to  cause performance degradation of the global model. Recently, a wealth of existing works that rely on linear relationships between local models have been proposed to defend against Byzantine attacks. Unfortunately, Byzantine attackers can easily circumvent these defenses in non-independent identically distributed (non-IID) scenarios, stemming mostly from the high dimensionality of local models and the intricate non-linear relationships among local models. In this paper, we propose Basalt, a robust FL framework designed to defend against Byzantine attacks while enhancing the performance global model in non-IID scenarios. Basalt builds an efficient detector that captures the  non-linear relationships among high-dimensional models to support the accurate identification of malicious clients. Furthermore, it introduces a heuristic aggregation mechanism based on generalization capability, aiming at boosting global model performance. Our extensive experimental analysis shows Basalt's superior performance over existing defense methods. Especially, it achieves 100\% accuracy in detecting malicious activity on the MNIST dataset.
